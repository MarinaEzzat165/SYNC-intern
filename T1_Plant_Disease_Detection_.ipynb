{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkbRhFmOLOg3"
      },
      "source": [
        "#Plant Disease Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLV8y6PcLOT-"
      },
      "source": [
        "#Connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruIT3zrPKoA2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprigzpxLNa6"
      },
      "source": [
        "#Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l62VBSCyLn00"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tkinter as tk\n",
        "from tensorflow import keras\n",
        "from tkinter import filedialog\n",
        "from PIL import Image, ImageTk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfZ14XBXLyqX"
      },
      "source": [
        "#Read The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTx0x-XZL6On"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/dataset /color\"\n",
        "\n",
        "train_images = keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    label_mode='categorical'  # Ensure labels are one-hot encoded\n",
        ")\n",
        "\n",
        "test_images = keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    label_mode='categorical'  # Ensure labels are one-hot encoded\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1RUZ_X1pHd_"
      },
      "outputs": [],
      "source": [
        "# Function to load image data using cv2.imread\n",
        "def load_image(file_path):\n",
        "    full_path = os.path.join(dataset_path, file_path)  # Corrected path\n",
        "    img = cv2.imread(full_path)\n",
        "    if img is None:\n",
        "        print(f\"Error loading image: {full_path}\")\n",
        "        return None\n",
        "    img = cv2.resize(img, (224,224)) # image size\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6J4bkejph9o"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_path, percentage=100):\n",
        "    image_files = os.listdir(dataset_path)\n",
        "\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    for label, class_folder in enumerate(sorted(image_files)):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "        class_images = [os.path.join(class_path, img) for img in sorted(os.listdir(class_path))]\n",
        "\n",
        "        # Calculate how many images to load based on the percentage\n",
        "        num_images_to_load = int(len(class_images) * (percentage / 100.0))\n",
        "\n",
        "        # Get a subset of images based on the calculated number\n",
        "        selected_images = class_images[:num_images_to_load]\n",
        "\n",
        "        for img_path in selected_images:\n",
        "            if load_image(img_path) is not None:  # Ensure the image is successfully loaded\n",
        "                all_images.append(img_path)\n",
        "                all_labels.append(label)\n",
        "\n",
        "    return all_images, all_labels\n",
        "\n",
        "# Example usage\n",
        "all_images, all_labels = load_dataset(dataset_path)\n",
        "\n",
        "# Example: print the first 10 image paths and their labels\n",
        "for img_path, label in zip(all_images[:10], all_labels[:10]):\n",
        "    print(f'{img_path}: {label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWczdJK0tosg"
      },
      "outputs": [],
      "source": [
        "classes = train_images.class_names\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yLaHt4rQOcC"
      },
      "source": [
        "#Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQT_AtYbQFI1"
      },
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays, skipping any None values\n",
        "loaded_images = [load_image(file_path) for file_path in all_images]\n",
        "images = np.array([img for img in loaded_images if img is not None])\n",
        "labels = np.array([label for img, label in zip(loaded_images, all_labels) if img is not None])\n",
        "print(\"done convert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n_VLzAhrRhx"
      },
      "outputs": [],
      "source": [
        "# Split the labels into training and testing sets\n",
        "train_labels, test_labels = train_test_split( labels, test_size=0.2, random_state=42)\n",
        "print(\"done split\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X1dM03qQGTp"
      },
      "outputs": [],
      "source": [
        "# Convert labels to one-hot encoding\n",
        "#train_labels_onehot = to_categorical(train_labels)\n",
        "#test_labels_onehot = to_categorical(test_labels)\n",
        "\n",
        "train_labels_onehot = to_categorical(train_labels, num_classes=38)\n",
        "test_labels_onehot = to_categorical(test_labels, num_classes=38)\n",
        "print(\"done convert \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDqNcsTr3xMQ"
      },
      "outputs": [],
      "source": [
        "# Use the labels generated by image_dataset_from_directory\n",
        "train_labels = train_images.map(lambda x, y: y)\n",
        "test_labels = test_images.map(lambda x, y: y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQDSIEygL-nV"
      },
      "source": [
        "#Extracting features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG0ax_T5N7Eo"
      },
      "outputs": [],
      "source": [
        "# Feature extraction model using VGG16 as base model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = True  # Freeze the weights of the VGG16 base model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvxI5gONPB7M"
      },
      "source": [
        "#Build CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L0U9-pCN8t1"
      },
      "outputs": [],
      "source": [
        "# Custom CNN model\n",
        "model = keras.models.Sequential([\n",
        "    # Feature extraction layers (VGG16)\n",
        "    base_model,\n",
        "\n",
        "    # Add a Global Average Pooling layer\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "    # Fully connected layers\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(12, activation='softmax') # Assuming 38 classes for output\n",
        "    #keras.models.add(Dense(38, activation='softmax'))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASvRlotJOAl6"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Assuming train_labels_onehot and test_labels_onehot are one-hot encoded labels\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CYHZaXo-93X"
      },
      "outputs": [],
      "source": [
        "# Example of printing labels and predictions for a batch\n",
        "for images, labels in train_images.take(1):\n",
        "    predictions = model.predict(images)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "    print(\"Predictions shape:\", predictions.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxxyEP0hPIAu"
      },
      "source": [
        "#Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pG8uGNxXPLrI"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "#history = model.fit(train_images , epochs = 20,validation_data = test_images)\n",
        "\n",
        "\"\"\"# Train the model\n",
        "history = model.fit(\n",
        "                    train_images,\n",
        "                    train_labels,\n",
        "                    epochs=20,\n",
        "                    validation_data=(test_images, test_labels))\"\"\"\n",
        "\n",
        "# Train the model using the labels from the dataset\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    epochs=10,\n",
        "    validation_data=test_images,\n",
        "    validation_steps=len(test_images),\n",
        ")\n",
        "\n",
        "\"\"\"# Train the model\n",
        "history = model.fit(train_images, train_labels_onehot,\n",
        "          epochs=20,\n",
        "          validation_data=(test_images, test_labels_onehot)) \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqboK2C-RDU0"
      },
      "outputs": [],
      "source": [
        "accuracy = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "epochs = range(1,21)\n",
        "\n",
        "plt.plot(epochs , accuracy , label = 'Acuuracy')\n",
        "plt.plot(epochs , loss , label = 'loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT7bpXKRRL0p"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4d21IagRdUA"
      },
      "source": [
        "#Test model predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv2zk6U7RTxg"
      },
      "outputs": [],
      "source": [
        "def img_to_pred(image):\n",
        "    image = image.numpy()\n",
        "    image = tf.expand_dims(image,0)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwYmAJhmRkbt"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,18))\n",
        "for images, labels in test_images.take(1) : # take the first patch\n",
        "  for i in range(1,10):\n",
        "    plt.subplot(3,3,i)\n",
        "    plt.imshow(images[i].numpy().astype('uint32'))\n",
        "    plt.axis('off')\n",
        "    actual = classes[labels[i]]\n",
        "    predict =classes[np.argmax( model.predict(img_to_pred(images[i])))]\n",
        "    plt.title(f\"actual : {actual}  \\n predicted : {predict} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IOH3iDfRrQ1"
      },
      "outputs": [],
      "source": [
        "model.save('Plant_disease.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}